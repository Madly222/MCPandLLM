import sys
import logging
from pathlib import Path
from typing import List
from dotenv import load_dotenv

load_dotenv()

sys.path.insert(0, str(Path(__file__).parent.parent))

from vector_store import vector_store  # ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π
from tools.utils import BASE_FILES_DIR
from tools.file_tool import read_file
from tools.excel_tool import read_excel

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# ---------------------- CHUNKING ----------------------

def chunk_text_with_overlap(text: str, max_words: int = 500, overlap_words: int = 50) -> List[str]:
    """–†–∞–∑–±–∏–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —á–∞–Ω–∫–∏ —Å overlap –ø–æ —Å–ª–æ–≤–∞–º"""
    words = text.split()
    if len(words) <= max_words:
        return [text]

    chunks = []
    start = 0
    while start < len(words):
        end = min(start + max_words, len(words))
        chunk = " ".join(words[start:end])
        chunks.append(chunk)
        start += (max_words - overlap_words)

    return chunks


def read_content(filepath: Path) -> str:
    """–ß–∏—Ç–∞–µ—Ç —Ñ–∞–π–ª –∏ –≤—Å–µ–≥–¥–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä–æ–∫—É"""
    if filepath.suffix.lower() in ['.xlsx', '.xls', '.csv']:
        content = read_excel(str(filepath))  # ‚úÖ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–Ω—ã–π –ø—É—Ç—å
        if isinstance(content, list):
            return "\n".join(str(row) for row in content)
        return str(content)

    return str(read_file(filepath))

def is_table_file(filepath: Path) -> bool:
    return filepath.suffix.lower() in ['.xlsx', '.xls', '.csv']


# ---------------------- INDEXING ----------------------

def index_file(filepath: Path) -> dict:
    """–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –±–µ–∑ —á–∞–Ω–∫–æ–≤–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü"""
    if not filepath.exists():
        return {"success": False, "message": "–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω"}

    try:
        content = read_content(filepath)

        if not content or str(content).startswith(("–û—à–∏–±–∫–∞", "–§–∞–π–ª")):
            return {"success": False, "message": "–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞"}

        content = str(content)

        # -----------------------------------------------------
        # 1. –¢–∞–±–ª–∏—Ü—ã ‚Äî –ù–ò–ö–û–ì–î–ê –ù–ï –†–ê–ó–ë–ò–í–ê–ï–ú –ù–ê –ß–ê–ù–ö–ò
        # -----------------------------------------------------
        if is_table_file(filepath):
            result = vector_store.add_document(
                content=content,
                filename=filepath.name,
                filetype=filepath.suffix.lstrip('.'),
                user_id = "default",
                metadata={
                    "chunk_index": 0,
                    "total_chunks": 1,
                    "source_path": str(filepath),
                    "is_table": True
                }
            )
            logger.info(f"üìä {filepath.name}: 1 —á–∞–Ω–∫ (—Ç–∞–±–ª–∏—Ü–∞ –±–µ–∑ —Ä–∞–∑–±–∏–µ–Ω–∏—è)")
            return {"success": True, "chunks": 1}

        # -----------------------------------------------------
        # 2. –û–±—ã—á–Ω—ã–µ —Ñ–∞–π–ª—ã ‚Äî —á–∞–Ω–∫–æ–≤–∞–Ω–∏–µ
        # -----------------------------------------------------
        chunks = chunk_text_with_overlap(content, max_words=500, overlap_words=50)

        for idx, chunk in enumerate(chunks):
            result = vector_store.add_document(
                content=chunk,
                filename=filepath.name,
                filetype=filepath.suffix.lstrip('.'),
                user_id="default",
                metadata={
                    "chunk_index": idx,
                    "total_chunks": len(chunks),
                    "source_path": str(filepath)
                }
            )

            if not result.get("success"):
                logger.warning(f"–û—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ —á–∞–Ω–∫–∞ {idx} –∏–∑ {filepath.name}")

        logger.info(f"üìÑ {filepath.name}: {len(chunks)} —á–∞–Ω–∫–æ–≤")
        return {"success": True, "chunks": len(chunks)}

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ {filepath.name}: {e}")
        return {"success": False, "message": str(e)}


# ---------------------- INDEX ALL ----------------------

def index_all_files():
    """–ú–∞—Å—Å–æ–≤–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤"""
    if not vector_store.is_connected():
        if not vector_store.connect():
            logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Weaviate")
            return

    supported = {'.txt', '.pdf', '.docx', '.xlsx', '.xls', '.md', '.csv', '.log'}

    all_files = [
        f for f in BASE_FILES_DIR.iterdir()
        if f.is_file() and f.suffix.lower() in supported
    ]

    if not all_files:
        logger.warning(f"‚ö†Ô∏è –§–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ {BASE_FILES_DIR}")
        return

    logger.info(f"üìÅ –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(all_files)}")

    ok, bad = 0, 0

    for filepath in all_files:
        result = index_file(filepath)
        if result.get("success"):
            ok += 1
        else:
            bad += 1

    logger.info(f"\n{'=' * 50}")
    logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ: {ok} | ‚ùå –û—à–∏–±–∫–∏: {bad}")
    logger.info(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {vector_store.get_stats()}")
    logger.info(f"{'=' * 50}\n")


# ---------------------- RECHUNK ALL ----------------------

def rechunk_all():
    """–£–¥–∞–ª—è–µ—Ç –í–°–ï —Å—Ç–∞—Ä—ã–µ —á–∞–Ω–∫–∏ –∏ —Å–æ–∑–¥–∞—ë—Ç –Ω–æ–≤—ã–µ"""
    logger.info("üßπ –£–¥–∞–ª–µ–Ω–∏–µ –≤—Å–µ—Ö —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è...")
    vector_store.clear_user_data()

    logger.info("‚ôªÔ∏è –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö —á–∞–Ω–∫–æ–≤...")
    index_all_files()

    logger.info("‚úÖ –ü–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–µ —á–∞–Ω–∫–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")


# ---------------------- REINDEX SINGLE FILE ----------------------

def reindex_file(filename: str):
    """
    –ü–æ–ª–Ω–∞—è –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –û–î–ù–û–ì–û —Ñ–∞–π–ª–∞:
    - —É–¥–∞–ª—è–µ—Ç —Ç–æ–ª—å–∫–æ –µ–≥–æ —Å—Ç–∞—Ä—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
    - —Å–æ–∑–¥–∞—ë—Ç –Ω–æ–≤—ã–µ —á–∞–Ω–∫–∏
    """
    logger.info(f"üßπ –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–∞: {filename}")

    # –£–¥–∞–ª—è–µ–º —Ç–æ–ª—å–∫–æ —ç—Ç–æ—Ç —Ñ–∞–π–ª –∏–∑ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ Document
    collection = vector_store.client.collections.get("Document")

    from weaviate.classes.query import Filter
    collection.data.delete_many(
        where=Filter.by_property("filename").equal(filename)
    )

    filepath = BASE_FILES_DIR / filename

    if not filepath.exists():
        logger.error(f"‚ùå –§–∞–π–ª {filename} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ BASE_FILES_DIR")
        return

    logger.info(f"üîÑ –ü–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è —Ñ–∞–π–ª–∞: {filename}")
    index_file(filepath)

    logger.info(f"‚úÖ –ü–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è —Ñ–∞–π–ª–∞ {filename} –∑–∞–≤–µ—Ä—à–µ–Ω–∞")


# ---------------------- MAIN ----------------------

if __name__ == "__main__":
    if not vector_store.connect():
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Weaviate")
        sys.exit(1)

    file_name = sys.argv[1] if len(sys.argv) > 1 else None

    if file_name:
        reindex_file(file_name)
    else:
        rechunk_all()

    vector_store.disconnect()
# agent/agent.py
from agent.memory import memory
from agent.router import route_message
from agent.prompts import SYSTEM_PROMPT
from agent.models import send_to_llm
from vector_store import vector_store
from tools.search_tool import get_rag_context
import logging

logger = logging.getLogger(__name__)

# === –õ–ò–ú–ò–¢–´ ===
MAX_HISTORY_MESSAGES = 10  # –ú–∞–∫—Å–∏–º—É–º —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –∏—Å—Ç–æ—Ä–∏–∏
MAX_RAG_CONTEXT_CHARS = 4000  # –ú–∞–∫—Å–∏–º—É–º —Å–∏–º–≤–æ–ª–æ–≤ RAG –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
MAX_TOTAL_PROMPT_CHARS = 12000  # –û–±—â–∏–π –ª–∏–º–∏—Ç –ø—Ä–æ–º–ø—Ç–∞
MAX_OUTPUT_TOKENS = 2048  # –¢–æ–∫–µ–Ω—ã –Ω–∞ –æ—Ç–≤–µ—Ç


def _estimate_tokens(text: str) -> int:
    """–ì—Ä—É–±–∞—è –æ—Ü–µ–Ω–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤ (1 —Ç–æ–∫–µ–Ω ‚âà 4 —Å–∏–º–≤–æ–ª–∞ –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ)"""
    return len(text) // 3


def _trim_history(history: list, max_messages: int = MAX_HISTORY_MESSAGES) -> list:
    """–û–±—Ä–µ–∑–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é, —Å–æ—Ö—Ä–∞–Ω—è—è –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è"""
    if len(history) <= max_messages:
        return history

    # –í—Å–µ–≥–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å–∏—Å—Ç–µ–º–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –µ—Å–ª–∏ –µ—Å—Ç—å
    trimmed = history[-max_messages:]
    logger.info(f"üìú –ò—Å—Ç–æ—Ä–∏—è –æ–±—Ä–µ–∑–∞–Ω–∞: {len(history)} ‚Üí {len(trimmed)} —Å–æ–æ–±—â–µ–Ω–∏–π")
    return trimmed


def _trim_context(context: str, max_chars: int = MAX_RAG_CONTEXT_CHARS) -> str:
    """–û–±—Ä–µ–∑–∞–µ—Ç RAG –∫–æ–Ω—Ç–µ–∫—Å—Ç"""
    if len(context) <= max_chars:
        return context

    trimmed = context[:max_chars] + "\n...[–∫–æ–Ω—Ç–µ–∫—Å—Ç –æ–±—Ä–µ–∑–∞–Ω –∏–∑-–∑–∞ –ª–∏–º–∏—Ç–∞]"
    logger.info(f"üìÑ –ö–æ–Ω—Ç–µ–∫—Å—Ç –æ–±—Ä–µ–∑–∞–Ω: {len(context)} ‚Üí {max_chars} —Å–∏–º–≤–æ–ª–æ–≤")
    return trimmed


async def agent_process(prompt: str, user_id: str):
    # –ü–æ–ª—É—á–∞–µ–º –∏ –æ–±—Ä–µ–∑–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é
    history = memory.get_history(user_id) or []
    history = _trim_history(history, MAX_HISTORY_MESSAGES)

    # –ü–æ–ª—É—á–∞–µ–º –∏ –æ–±—Ä–µ–∑–∞–µ–º RAG –∫–æ–Ω—Ç–µ–∫—Å—Ç
    rag_context = _build_rag_context(prompt, user_id)
    rag_context = _trim_context(rag_context, MAX_RAG_CONTEXT_CHARS)

    # –°–æ–±–∏—Ä–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
    enhanced_system_prompt = SYSTEM_PROMPT
    if rag_context:
        enhanced_system_prompt += f"\n\n{rag_context}"

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—â–∏–π —Ä–∞–∑–º–µ—Ä
    messages = [{"role": "system", "content": enhanced_system_prompt}] + history
    messages.append({"role": "user", "content": prompt})

    total_chars = sum(len(m["content"]) for m in messages)

    # –ï—Å–ª–∏ –≤—Å—ë –µ—â—ë —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ ‚Äî —Ä–µ–∂–µ–º –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–µ–µ
    if total_chars > MAX_TOTAL_PROMPT_CHARS:
        logger.warning(f"‚ö†Ô∏è –ü—Ä–æ–º–ø—Ç —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π ({total_chars} —Å–∏–º–≤–æ–ª–æ–≤), –æ–±—Ä–µ–∑–∞–µ–º...")

        # –£–±–∏—Ä–∞–µ–º RAG –∫–æ–Ω—Ç–µ–∫—Å—Ç
        if rag_context:
            enhanced_system_prompt = SYSTEM_PROMPT
            messages = [{"role": "system", "content": enhanced_system_prompt}] + history
            messages.append({"role": "user", "content": prompt})
            total_chars = sum(len(m["content"]) for m in messages)

        # –ï—Å–ª–∏ –≤—Å—ë –µ—â—ë –º–Ω–æ–≥–æ ‚Äî —Ä–µ–∂–µ–º –∏—Å—Ç–æ—Ä–∏—é —Å–∏–ª—å–Ω–µ–µ
        if total_chars > MAX_TOTAL_PROMPT_CHARS:
            history = history[-4:]  # –¢–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 4 —Å–æ–æ–±—â–µ–Ω–∏—è
            messages = [{"role": "system", "content": enhanced_system_prompt}] + history
            messages.append({"role": "user", "content": prompt})

    logger.info(f"üìä –†–∞–∑–º–µ—Ä –ø—Ä–æ–º–ø—Ç–∞: ~{_estimate_tokens(str(messages))} —Ç–æ–∫–µ–Ω–æ–≤")

    if vector_store.is_connected():
        vector_store.add_chat_message(prompt, "user", user_id)

    result, updated_messages = await route_message(messages, user_id)

    if result is None:
        logger.info("–û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞ LLM")
        result = await send_to_llm(updated_messages, max_tokens=MAX_OUTPUT_TOKENS)
        updated_messages.append({"role": "assistant", "content": result})

    if vector_store.is_connected():
        vector_store.add_chat_message(result, "assistant", user_id)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—Ä–µ–∑–∞–Ω–Ω—É—é –∏—Å—Ç–æ—Ä–∏—é
    memory.set_history(user_id, updated_messages[-MAX_HISTORY_MESSAGES:])
    return result


def _build_rag_context(query: str, user_id: str, max_length: int = MAX_RAG_CONTEXT_CHARS) -> str:
    """–°–æ–±–∏—Ä–∞–µ—Ç RAG –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å —É—á—ë—Ç–æ–º –ª–∏–º–∏—Ç–æ–≤"""
    if not vector_store.is_connected():
        return ""

    try:
        context_parts = []

        # –î–æ–∫—É–º–µ–Ω—Ç—ã ‚Äî –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
        doc_context = get_rag_context(query, user_id, top_n=3)  # –£–º–µ–Ω—å—à–∏–ª —Å 5 –¥–æ 3
        if doc_context:
            context_parts.append(doc_context)

        # –ü–∞–º—è—Ç—å ‚Äî —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –º–µ—Å—Ç–æ
        current_len = len("\n".join(context_parts))
        if current_len < max_length * 0.7:
            user_facts = vector_store.search_memory(query, user_id, limit=2)
            if user_facts:
                context_parts.append("\n=== –ü–ê–ú–Ø–¢–¨ ===")
                for fact in user_facts:
                    context_parts.append(f"‚Ä¢ {fact}")

        # –ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞ ‚Äî —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –º–µ—Å—Ç–æ
        current_len = len("\n".join(context_parts))
        if current_len < max_length * 0.8:
            chat_history = vector_store.search_chat_history(query, user_id, limit=2)
            if chat_history:
                context_parts.append("\n=== –ò–ó –ü–†–û–®–õ–´–• –†–ê–ó–ì–û–í–û–†–û–í ===")
                for chat in chat_history:
                    msg = chat["message"][:150]
                    context_parts.append(f"‚Ä¢ {msg}")

        full_context = "\n".join(context_parts)
        return full_context[:max_length]

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ RAG –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {e}")
        return ""
import os
import re
import json
import logging
from pathlib import Path
from typing import Optional, Tuple, List

from agent.memory import memory
from tools.file_tool import try_handle_file_command, select_file
from tools.excel_tool import read_excel, read_excel_for_edit
from tools.search_tool import perform_search, smart_search
from tools.edit_excel_tool import edit_excel, get_excel_preview
from tools.excel_nlu import parse_excel_command
from tools.multi_file_tool import process_multiple_files
from tools.file_reader_tool import get_example_files, find_file
from tools.file_generator_tool import generate_file
from vector_store import vector_store

logger = logging.getLogger(__name__)

BASE_DIR = Path(__file__).resolve().parent.parent
STORAGE_DIR = Path(os.getenv("FILES_DIR", BASE_DIR / "storage"))


def get_role_files_dir(role: str) -> Path:
    return STORAGE_DIR / role


EDIT_TRIGGERS = [
    r"–¥–æ–±–∞–≤—å —Å—Ç—Ä–æ–∫—É",
    r"–¥–æ–±–∞–≤—å –∫–æ–ª–æ–Ω–∫—É",
    r"—É–¥–∞–ª–∏ —Å—Ç—Ä–æ–∫—É",
    r"—É–¥–∞–ª–∏ –∫–æ–ª–æ–Ω–∫—É",
    r"–∏–∑–º–µ–Ω–∏ —è—á–µ–π–∫—É",
    r"–ø–æ–º–µ–Ω—è–π —è—á–µ–π–∫—É",
    r"–≤—Å—Ç–∞–≤—å —Å—Ç—Ä–æ–∫—É",
    r"–Ω–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞",
    r"–Ω–æ–≤–∞—è –∫–æ–ª–æ–Ω–∫–∞",
    r"–æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π",
    r"—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π",
    r"–∏–∑–º–µ–Ω–∏ –≤ —Ñ–∞–π–ª–µ",
    r"–∏–∑–º–µ–Ω–∏ —Ñ–∞–π–ª",
    r"–æ–±–Ω–æ–≤–∏ —Ñ–∞–π–ª",
    r"—É–¥–∞–ª–∏.*—Ä–∞–±–æ—Ç",
    r"—É–¥–∞–ª–∏.*—Å—Ç—Ä–æ–∫",
    r"–¥–æ–±–∞–≤—å.*–≤ —Ñ–∞–π–ª",
    r"–¥–æ–±–∞–≤—å.*–≤ —Ç–∞–±–ª–∏—Ü",
]

GENERATE_TRIGGERS = [
    r"—Å–æ–∑–¥–∞–π.*–∏–∑.*—Ñ–∞–π–ª",
    r"—Å–¥–µ–ª–∞–π.*–∏–∑.*—Ñ–∞–π–ª",
    r"–æ–±—ä–µ–¥–∏–Ω–∏.*—Ñ–∞–π–ª",
    r"—Å–æ–±–µ—Ä–∏.*–∏–∑",
    r"—Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π.*–∏–∑",
    r"—Å–æ–∑–¥–∞–π.*–æ–±—ä–µ–¥–∏–Ω–∏–≤",
    r"—Å–¥–µ–ª–∞–π.*–æ–±—ä–µ–¥–∏–Ω–∏–≤",
    r"–∏–∑ —Ñ–∞–π–ª–∞.*–∏.*—Ñ–∞–π–ª–∞.*—Å–æ–∑–¥–∞–π",
    r"–∏–∑ —Ñ–∞–π–ª–∞.*–∏.*—Ñ–∞–π–ª–∞.*—Å–¥–µ–ª–∞–π",
    r"–ø–æ –ø—Ä–∏–º–µ—Ä—É.*—Å–æ–∑–¥–∞–π",
    r"–ø–æ —à–∞–±–ª–æ–Ω—É.*—Å–æ–∑–¥–∞–π",
    r"–∫–∞–∫ –≤ –ø—Ä–∏–º–µ—Ä–µ",
    r"–∫–∞–∫ –≤ examples",
    r"–∏—Å–ø–æ–ª—å–∑—É—è.*—à–∞–±–ª–æ–Ω",
    r"—Å–æ–∑–¥–∞–π.*excel",
    r"—Å–æ–∑–¥–∞–π.*word",
    r"—Å–æ–∑–¥–∞–π.*xlsx",
    r"—Å–æ–∑–¥–∞–π.*docx",
    r"—Å–¥–µ–ª–∞–π.*–æ—Ç—á—ë—Ç.*–∏–∑",
    r"—Å–¥–µ–ª–∞–π.*–æ—Ç—á–µ—Ç.*–∏–∑",
    r"—Å–æ–∑–¥–∞–π.*–æ—Ç—á—ë—Ç.*–∏–∑",
    r"—Å–æ–∑–¥–∞–π.*–æ—Ç—á–µ—Ç.*–∏–∑",
    r"—Å–æ–∑–¥–∞–π –Ω–æ–≤—ã–π",
    r"—Å–¥–µ–ª–∞–π –Ω–æ–≤—ã–π",
    r"–Ω–æ–≤—ã–π —Ñ–∞–π–ª –∏–∑",
]


def _is_edit_command(text: str) -> bool:
    text_lower = text.lower()
    for trigger in EDIT_TRIGGERS:
        if re.search(trigger, text_lower):
            return True
    return False


def _is_generate_command(text: str) -> bool:
    text_lower = text.lower()
    for trigger in GENERATE_TRIGGERS:
        if re.search(trigger, text_lower):
            return True
    return False


def _extract_files_from_generate_command(text: str, role: str) -> Tuple[
    List[str], Optional[str], Optional[str], Optional[str]]:
    source_files = []
    output_format = None
    output_name = None
    template = None

    text_lower = text.lower()

    if 'excel' in text_lower or 'xlsx' in text_lower or '—Ç–∞–±–ª–∏—Ü' in text_lower:
        output_format = 'xlsx'
    elif 'word' in text_lower or 'docx' in text_lower or '–¥–æ–∫—É–º–µ–Ω—Ç' in text_lower:
        output_format = 'docx'
    else:
        output_format = 'xlsx'

    template_match = re.search(r'(?:–ø–æ –ø—Ä–∏–º–µ—Ä—É|–ø–æ —à–∞–±–ª–æ–Ω—É|–∫–∞–∫ –≤|–∏—Å–ø–æ–ª—å–∑—É—è —à–∞–±–ª–æ–Ω)\s+["\']?([^\s"\']+)["\']?', text,
                               re.I)
    if template_match:
        template = template_match.group(1)

    examples_match = re.search(r'(?:–∏–∑|–∏–∑ –ø–∞–ø–∫–∏)\s+examples?\s*[/\\]?\s*([^\s,]+)', text, re.I)
    if examples_match:
        template = examples_match.group(1)

    output_match = re.search(r'(?:–Ω–∞–∑–æ–≤–∏|—Å–æ—Ö—Ä–∞–Ω–∏ –∫–∞–∫|–∏–º—è —Ñ–∞–π–ª–∞)\s+["\']?([a-zA-Z–∞-—è–ê-–Ø0-9_\-]+)["\']?', text, re.I)
    if output_match:
        output_name = output_match.group(1)

    file_patterns = [
        r'–∏–∑\s+(?:—Ñ–∞–π–ª–æ–≤?\s+)?["\']?([^\s"\']+\.(?:xlsx?|docx|pdf|pptx))["\']?',
        r'(?:—Ñ–∞–π–ª[–∞—ã]?\s+)?["\']?([^\s"\']+\.(?:xlsx?|docx|pdf|pptx))["\']?',
        r'–∏\s+["\']?([^\s"\']+\.(?:xlsx?|docx|pdf|pptx))["\']?',
    ]

    found_files = set()
    for pattern in file_patterns:
        matches = re.findall(pattern, text, re.I)
        for match in matches:
            if match and match != template:
                found_files.add(match)

    role_dir = STORAGE_DIR / role
    if role_dir.exists():
        for filepath in role_dir.iterdir():
            if filepath.is_file():
                name_lower = filepath.stem.lower()
                if name_lower in text_lower or filepath.name.lower() in text_lower:
                    if filepath.suffix.lower() in ['.xlsx', '.xls', '.docx', '.pdf', '.pptx']:
                        found_files.add(filepath.name)

    source_files = list(found_files)

    return source_files, output_format, output_name, template


def _extract_filename_from_text(text: str, role: str) -> Optional[str]:
    text_lower = text.lower()
    role_dir = get_role_files_dir(role)

    if not role_dir.exists():
        return None

    best_match = None
    best_match_len = 0

    for filepath in role_dir.iterdir():
        if filepath.suffix.lower() in ['.xlsx', '.xls']:
            filename = filepath.name
            filename_lower = filename.lower()

            if filename_lower in text_lower:
                if len(filename) > best_match_len:
                    best_match = filename
                    best_match_len = len(filename)

            stem_lower = filepath.stem.lower()
            if stem_lower in text_lower:
                if len(filepath.stem) > best_match_len:
                    best_match = filename
                    best_match_len = len(filepath.stem)

    if best_match:
        logger.info(f"–ù–∞–π–¥–µ–Ω —Ñ–∞–π–ª –ø–æ —Ç–æ—á–Ω–æ–º—É —Å–æ–≤–ø–∞–¥–µ–Ω–∏—é: {best_match}")
        return best_match

    xlsx_match = re.search(r'(\S+\.xlsx?)', text, re.I)
    if xlsx_match:
        potential_name = xlsx_match.group(1)
        found = _find_file_by_pattern(potential_name, role)
        if found:
            logger.info(f"–ù–∞–π–¥–µ–Ω —Ñ–∞–π–ª –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É: {found}")
            return found

    keywords = []
    for word in text.split():
        word_clean = re.sub(r'[^\w]', '', word.lower())
        if word_clean and len(word_clean) >= 3:
            if word_clean not in ['–æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π', '—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π', '–∏–∑–º–µ–Ω–∏', '—É–¥–∞–ª–∏',
                                  '–¥–æ–±–∞–≤—å', '—Ñ–∞–π–ª', '—Ç–∞–±–ª–∏—Ü—É', '—Ç–∞–±–ª–∏—Ü–∞', 'excel',
                                  '—Å—Ç—Ä–æ–∫—É', '—Å—Ç—Ä–æ–∫–∏', '–∫–æ–ª–æ–Ω–∫—É', '—è—á–µ–π–∫—É', '—Ä–∞–±–æ—Ç—ã',
                                  '–≤—Å–µ', '–≤—ã–ø–æ–ª–Ω–µ–Ω—ã–µ', '–≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ', '–Ω–µ–≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ']:
                keywords.append(word_clean)

    if keywords:
        best_file = None
        best_score = 0

        for filepath in role_dir.iterdir():
            if filepath.suffix.lower() in ['.xlsx', '.xls']:
                stem_lower = filepath.stem.lower()
                score = sum(1 for kw in keywords if kw in stem_lower)
                if score > best_score:
                    best_score = score
                    best_file = filepath.name

        if best_file:
            logger.info(f"–ù–∞–π–¥–µ–Ω —Ñ–∞–π–ª –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º ({best_score} —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π): {best_file}")
            return best_file

    return None


def _find_file_by_pattern(pattern: str, role: str) -> Optional[str]:
    if not pattern:
        return None

    role_dir = get_role_files_dir(role)
    if not role_dir.exists():
        return None

    pattern_clean = pattern.lower().replace('.xlsx', '').replace('.xls', '')
    pattern_clean = re.sub(r'[^\w]', '', pattern_clean)

    best_match = None
    best_score = 0

    for filepath in role_dir.iterdir():
        if filepath.suffix.lower() in ['.xlsx', '.xls']:
            stem_clean = re.sub(r'[^\w]', '', filepath.stem.lower())

            if pattern_clean == stem_clean:
                return filepath.name

            if pattern_clean in stem_clean:
                score = len(pattern_clean) / len(stem_clean)
                if score > best_score:
                    best_score = score
                    best_match = filepath.name

    return best_match


def _is_complex_edit_command(text: str) -> bool:
    complex_patterns = [
        r"—É–¥–∞–ª–∏.*–≤—Å–µ",
        r"—É–¥–∞–ª–∏.*–≤—ã–ø–æ–ª–Ω–µ–Ω",
        r"—É–¥–∞–ª–∏.*–Ω–µ–≤—ã–ø–æ–ª–Ω–µ–Ω",
        r"—É–¥–∞–ª–∏.*–≥–¥–µ",
        r"—É–¥–∞–ª–∏.*–∫–æ—Ç–æ—Ä—ã–µ",
        r"–∏–∑–º–µ–Ω–∏.*–≤—Å–µ",
        r"–∑–∞–º–µ–Ω–∏.*–≤—Å–µ",
        r"–ø–µ—Ä–µ—Å—á–∏—Ç–∞–π",
        r"–æ–±–Ω–æ–≤–∏.*–∏—Ç–æ–≥",
    ]

    text_lower = text.lower()
    for pattern in complex_patterns:
        if re.search(pattern, text_lower):
            return True
    return False


def _get_edit_instruction(text: str, filename: str) -> str:
    text_clean = text.lower()
    text_clean = re.sub(r'–æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π\s*', '', text_clean)
    text_clean = re.sub(r'—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π\s*', '', text_clean)
    text_clean = re.sub(r'[^\s]+\.xlsx?', '', text_clean, flags=re.I)
    text_clean = text_clean.strip()
    return text_clean


def _format_content_for_llm(content) -> str:
    parts = []

    if content.text:
        text_preview = content.text[:2000]
        if len(content.text) > 2000:
            text_preview += "\n... (—Ç–µ–∫—Å—Ç –æ–±—Ä–µ–∑–∞–Ω)"
        parts.append(f"–¢–µ–∫—Å—Ç:\n{text_preview}")

    for i, table in enumerate(content.tables):
        table_str = f"\n–¢–∞–±–ª–∏—Ü–∞ {i + 1}"
        if table.sheet_name:
            table_str += f" (–ª–∏—Å—Ç: {table.sheet_name})"
        table_str += ":\n"

        if table.headers:
            table_str += "| " + " | ".join(str(h) for h in table.headers) + " |\n"
            table_str += "| " + " | ".join(["---"] * len(table.headers)) + " |\n"

        for row in table.rows[:50]:
            table_str += "| " + " | ".join(str(cell) for cell in row) + " |\n"

        if len(table.rows) > 50:
            table_str += f"... –µ—â—ë {len(table.rows) - 50} —Å—Ç—Ä–æ–∫\n"

        parts.append(table_str)

    return "\n".join(parts) if parts else "(–ø—É—Å—Ç–æ–π —Ñ–∞–π–ª)"


def _create_file_from_llm_json(data: dict, output_format: str, output_name: str, sources: list, template: str) -> dict:
    from datetime import datetime
    from openpyxl import Workbook
    from openpyxl.styles import Font, Border, Side, Alignment
    from docx import Document
    from docx.shared import Pt
    from docx.enum.text import WD_ALIGN_PARAGRAPH

    try:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        sheets = data.get("sheets", [])
        title = data.get("title", "")

        if output_format in ['xlsx', 'excel', 'xls']:
            wb = Workbook()

            thin_border = Border(
                left=Side(style='thin'),
                right=Side(style='thin'),
                top=Side(style='thin'),
                bottom=Side(style='thin')
            )
            header_font = Font(bold=True)

            for sheet_idx, sheet_data in enumerate(sheets):
                if sheet_idx == 0:
                    ws = wb.active
                    ws.title = sheet_data.get("name", "–õ–∏—Å—Ç1")[:31]
                else:
                    ws = wb.create_sheet(title=sheet_data.get("name", f"–õ–∏—Å—Ç{sheet_idx + 1}")[:31])

                headers = sheet_data.get("headers", [])
                rows = sheet_data.get("rows", [])

                current_row = 1

                if headers:
                    for col_idx, header in enumerate(headers, 1):
                        cell = ws.cell(row=current_row, column=col_idx, value=header)
                        cell.font = header_font
                        cell.border = thin_border
                        cell.alignment = Alignment(horizontal='center')
                    current_row += 1

                for row_data in rows:
                    for col_idx, value in enumerate(row_data, 1):
                        cell = ws.cell(row=current_row, column=col_idx, value=value)
                        cell.border = thin_border
                    current_row += 1

                for col in ws.columns:
                    max_length = 0
                    column = col[0].column_letter
                    for cell in col:
                        try:
                            if cell.value:
                                max_length = max(max_length, len(str(cell.value)))
                        except:
                            pass
                    ws.column_dimensions[column].width = min(max_length + 2, 50)

            filename = f"{output_name}_{timestamp}.xlsx"
            filepath = STORAGE_DIR.parent / "downloads" / filename
            filepath.parent.mkdir(parents=True, exist_ok=True)

            wb.save(filepath)
            wb.close()

            download_url = f"{os.getenv('SERVER_URL', 'http://localhost:8000')}/download/{filename}"

            return {
                "success": True,
                "filename": filename,
                "download_url": download_url,
                "sheets_count": len(sheets)
            }

        elif output_format in ['docx', 'word', 'doc']:
            doc = Document()

            if title:
                heading = doc.add_heading(title, level=0)
                heading.alignment = WD_ALIGN_PARAGRAPH.CENTER

            for sheet_data in sheets:
                sheet_name = sheet_data.get("name", "")
                if sheet_name:
                    doc.add_heading(sheet_name, level=1)

                headers = sheet_data.get("headers", [])
                rows = sheet_data.get("rows", [])

                if headers or rows:
                    num_cols = len(headers) if headers else len(rows[0]) if rows else 0
                    num_rows = (1 if headers else 0) + len(rows)

                    if num_cols > 0 and num_rows > 0:
                        table = doc.add_table(rows=num_rows, cols=num_cols)
                        table.style = 'Table Grid'

                        if headers:
                            for idx, header in enumerate(headers):
                                cell = table.rows[0].cells[idx]
                                cell.text = str(header)
                                for p in cell.paragraphs:
                                    for run in p.runs:
                                        run.bold = True

                        start_row = 1 if headers else 0
                        for row_idx, row_data in enumerate(rows):
                            for col_idx, value in enumerate(row_data):
                                if col_idx < num_cols:
                                    table.rows[start_row + row_idx].cells[col_idx].text = str(value)

                        doc.add_paragraph()

            filename = f"{output_name}_{timestamp}.docx"
            filepath = STORAGE_DIR.parent / "downloads" / filename
            filepath.parent.mkdir(parents=True, exist_ok=True)

            doc.save(filepath)

            download_url = f"{os.getenv('SERVER_URL', 'http://localhost:8000')}/download/{filename}"

            return {
                "success": True,
                "filename": filename,
                "download_url": download_url,
                "sheets_count": len(sheets)
            }
        else:
            return {"success": False, "error": f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç: {output_format}"}

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ñ–∞–π–ª–∞ –∏–∑ JSON: {e}", exc_info=True)
        return {"success": False, "error": str(e)}


async def route_message(messages: list, role: str):
    last_user_msg = messages[-1]["content"]
    state = memory.get_state(role) or {}

    logger.info(f"Router: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º '{last_user_msg[:50]}...'")

    if state.get("awaiting_file_choice"):
        if state.get("awaiting_excel_choice"):
            from tools.excel_tool import select_excel_file
            chosen_text = select_excel_file(role, last_user_msg)
            state["awaiting_file_choice"] = False
            state["awaiting_excel_choice"] = False
            memory.set_state(role, state)
            return chosen_text, messages
        else:
            chosen_text = select_file(role, last_user_msg)
            state["awaiting_file_choice"] = False
            memory.set_state(role, state)
            return chosen_text, messages

    if state.get("awaiting_file_for_edit"):
        operations = state.get("pending_operations", [])
        filename = _find_file_by_pattern(last_user_msg, role)

        if filename:
            result = edit_excel(filename, operations, role=role)
            state["awaiting_file_for_edit"] = False
            state["pending_operations"] = None
            memory.set_state(role, state)

            if result.get("success"):
                return f"–ì–æ—Ç–æ–≤–æ! –°–∫–∞—á–∞—Ç—å: {result['download_url']}", messages
            else:
                return f"–û—à–∏–±–∫–∞: {result.get('error')}", messages
        else:
            return "–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω. –£–∫–∞–∂–∏—Ç–µ —Ç–æ—á–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞.", messages

    gen_match = re.search(
        r'```json\s*(\{[\s\S]*?"sheets"[\s\S]*?\})\s*```',
        last_user_msg,
        re.I
    )
    if gen_match and state.get("pending_file_generation"):
        try:
            gen_data = json.loads(gen_match.group(1))
            pending = state.get("pending_file_generation", {})

            result = _create_file_from_llm_json(
                gen_data,
                pending.get("output_format", "xlsx"),
                pending.get("output_name", "generated"),
                pending.get("sources", []),
                pending.get("template")
            )

            state["pending_file_generation"] = None
            memory.set_state(role, state)

            if result.get("success"):
                response = f"‚úÖ –§–∞–π–ª —Å–æ–∑–¥–∞–Ω: {result['filename']}\n\n"
                response += f"üìÅ –ò—Å—Ç–æ—á–Ω–∏–∫–∏: {', '.join(pending.get('sources', []))}\n"
                response += f"üìã –ü–æ —à–∞–±–ª–æ–Ω—É: {pending.get('template')}\n"
                response += f"üìä –¢–∞–±–ª–∏—Ü: {result.get('sheets_count', 0)}\n\n"
                response += f"üîó –°–∫–∞—á–∞—Ç—å: {result['download_url']}"
                return response, messages
            else:
                return f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ñ–∞–π–ª–∞: {result.get('error')}", messages

        except json.JSONDecodeError as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
            state["pending_file_generation"] = None
            memory.set_state(role, state)

    if _is_generate_command(last_user_msg):
        logger.info("Router: –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –∫–æ–º–∞–Ω–¥–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ñ–∞–π–ª–∞")

        if re.search(r'–ø–æ–∫–∞–∂–∏\s+–ø—Ä–∏–º–µ—Ä—ã|—Å–ø–∏—Å–æ–∫\s+–ø—Ä–∏–º–µ—Ä–æ–≤|—á—Ç–æ\s+–µ—Å—Ç—å\s+–≤\s+examples|—à–∞–±–ª–æ–Ω—ã|—Å–ø–∏—Å–æ–∫ —à–∞–±–ª–æ–Ω–æ–≤',
                     last_user_msg, re.I):
            examples = get_example_files()
            if examples:
                examples_list = "\n".join([f"- {e['name']} ({e['type']})" for e in examples])
                return f"üìÅ –î–æ—Å—Ç—É–ø–Ω—ã–µ —à–∞–±–ª–æ–Ω—ã –≤ –ø–∞–ø–∫–µ examples:\n{examples_list}", messages
            else:
                return "–ü–∞–ø–∫–∞ examples –ø—É—Å—Ç–∞. –î–æ–±–∞–≤—å—Ç–µ —à–∞–±–ª–æ–Ω—ã –≤ storage/examples/", messages

        source_files, output_format, output_name, template = _extract_files_from_generate_command(last_user_msg, role)

        if not source_files:
            role_dir = STORAGE_DIR / role
            available_files = []
            if role_dir.exists():
                available_files = [f.name for f in role_dir.iterdir()
                                   if f.suffix.lower() in ['.xlsx', '.xls', '.docx', '.pdf', '.pptx']]

            if available_files:
                files_list = "\n".join([f"- {f}" for f in available_files[:15]])
                return f"–£–∫–∞–∂–∏—Ç–µ —Ñ–∞–π–ª—ã –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è.\n\nüìÅ –î–æ—Å—Ç—É–ø–Ω—ã–µ —Ñ–∞–π–ª—ã:\n{files_list}\n\nüí° –ü—Ä–∏–º–µ—Ä: '–°–æ–∑–¥–∞–π Excel –∏–∑ file1.xlsx –∏ file2.docx'", messages
            else:
                return "–§–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª—ã –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è.", messages

        if not output_name:
            output_name = "combined"

        if template:
            from tools.file_reader_tool import extract_content, read_multiple_files

            template_path = find_file(template, role)
            if not template_path:
                return f"‚ùå –®–∞–±–ª–æ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω: {template}", messages

            template_content = extract_content(template_path)
            source_contents = read_multiple_files(source_files, role)

            if not source_contents:
                return "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∏—Å—Ö–æ–¥–Ω—ã–µ —Ñ–∞–π–ª—ã", messages

            template_preview = _format_content_for_llm(template_content)
            sources_preview = "\n\n---\n\n".join([
                f"–§–ê–ô–õ: {c.filename}\n{_format_content_for_llm(c)}"
                for c in source_contents
            ])

            context = f"""–ó–ê–î–ê–ß–ê: –°–æ–∑–¥–∞—Ç—å —Ñ–∞–π–ª –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ —à–∞–±–ª–æ–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É—è –¥–∞–Ω–Ω—ã–µ –∏–∑ –∏—Å—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤.

–®–ê–ë–õ–û–ù ({template}):
{template_preview}

–ò–°–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï:
{sources_preview}

---

–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å—Ç—Ä—É–∫—Ç—É—Ä—É —à–∞–±–ª–æ–Ω–∞ –∏ –¥–∞–Ω–Ω—ã–µ –∏–∑ –∏—Å—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤.
–°–æ–∑–¥–∞–π JSON –∫–æ—Ç–æ—Ä—ã–π —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–µ —à–∞–±–ª–æ–Ω–∞, –Ω–æ —Å –¥–∞–Ω–Ω—ã–º–∏ –∏–∑ –∏—Å—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤.

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ - –¢–û–õ–¨–ö–û JSON:
```json
{{
  "output_format": "{output_format}",
  "output_name": "{output_name}",
  "title": "–ó–∞–≥–æ–ª–æ–≤–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞",
  "sheets": [
    {{
      "name": "–ù–∞–∑–≤–∞–Ω–∏–µ –ª–∏—Å—Ç–∞",
      "headers": ["–ö–æ–ª–æ–Ω–∫–∞1", "–ö–æ–ª–æ–Ω–∫–∞2", ...],
      "rows": [
        ["–∑–Ω–∞—á–µ–Ω–∏–µ1", "–∑–Ω–∞—á–µ–Ω–∏–µ2", ...],
        ...
      ]
    }}
  ]
}}
```

–í–∞–∂–Ω–æ:
- –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–æ–ª–∂–Ω–∞ –¢–û–ß–ù–û —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å —à–∞–±–ª–æ–Ω—É
- –î–∞–Ω–Ω—ã–µ –±–µ—Ä—É—Ç—Å—è –∏–∑ –∏—Å—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
- –û–±—ä–µ–¥–∏–Ω–∏ –ø–æ—Ö–æ–∂–∏–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ä–∞–∑–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
- –ï—Å–ª–∏ –≤ —à–∞–±–ª–æ–Ω–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑–¥–µ–ª–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä –ú–∞—Ç–µ—Ä–∏–∞–ª—ã –∏ –†–∞–±–æ—Ç—ã) - —Å–æ—Ö—Ä–∞–Ω–∏ —ç—Ç—É —Å—Ç—Ä—É–∫—Ç—É—Ä—É
"""
            messages.append({"role": "user", "content": context})

            state["pending_file_generation"] = {
                "output_format": output_format,
                "output_name": output_name,
                "sources": [c.filename for c in source_contents],
                "template": template
            }
            memory.set_state(role, state)

            logger.info(f"Router: –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ —à–∞–±–ª–æ–Ω—É, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ LLM")
            return None, messages

        title_match = re.search(r'(?:—Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º|–∑–∞–≥–æ–ª–æ–≤–æ–∫|title)\s+["\']?([^"\']+)["\']?', last_user_msg, re.I)
        title = title_match.group(1) if title_match else None

        include_images = '–±–µ–∑ –∫–∞—Ä—Ç–∏–Ω–æ–∫' not in last_user_msg.lower() and '–±–µ–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π' not in last_user_msg.lower()

        result = generate_file(
            source_files=source_files,
            output_format=output_format,
            output_name=output_name,
            title=title,
            template_name=None,
            include_images=include_images,
            role=role
        )

        if result.get("success"):
            response = f"‚úÖ –§–∞–π–ª —Å–æ–∑–¥–∞–Ω: {result['filename']}\n\n"
            response += f"üìÅ –ò—Å—Ç–æ—á–Ω–∏–∫–∏: {', '.join(result.get('sources', []))}\n"
            response += f"üìä –¢–∞–±–ª–∏—Ü: {result.get('tables_count', 0)}, "
            response += f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {result.get('images_count', 0)}\n\n"
            response += f"üîó –°–∫–∞—á–∞—Ç—å: {result['download_url']}"
            return response, messages
        else:
            return f"‚ùå –û—à–∏–±–∫–∞: {result.get('error')}", messages

    if _is_edit_command(last_user_msg):
        logger.info("Router: –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –∫–æ–º–∞–Ω–¥–∞ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
        filename = _extract_filename_from_text(last_user_msg, role)
        logger.info(f"Router: –∏–∑–≤–ª–µ—á—ë–Ω–Ω—ã–π —Ñ–∞–π–ª = {filename}")

        if not filename:
            results = smart_search(last_user_msg, role, limit=5)
            excel_files = [r for r in results if r.get("is_table")]

            if len(excel_files) == 1:
                filename = excel_files[0]["filename"]
            elif len(excel_files) > 1:
                files_list = "\n".join([f"- {f['filename']}" for f in excel_files])
                return f"–ù–∞–π–¥–µ–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–∞–π–ª–æ–≤:\n{files_list}\n\n–£–∫–∞–∂–∏—Ç–µ –∫–∞–∫–æ–π —Ñ–∞–π–ª —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å.", messages

        if not filename:
            role_dir = get_role_files_dir(role)
            all_excel = []
            if role_dir.exists():
                all_excel = [f.name for f in role_dir.iterdir()
                             if f.suffix.lower() in ['.xlsx', '.xls']]
            if all_excel:
                files_list = "\n".join([f"- {f}" for f in all_excel[:10]])
                return f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ñ–∞–π–ª. –î–æ—Å—Ç—É–ø–Ω—ã–µ —Ñ–∞–π–ª—ã:\n{files_list}", messages
            else:
                return "Excel —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.", messages

        if _is_complex_edit_command(last_user_msg):
            instruction = _get_edit_instruction(last_user_msg, filename)
            file_content = read_excel_for_edit(filename, role=role)

            context = f"""–§–∞–π–ª: {filename}

–í–ê–ñ–ù–û: –ö–æ–ª–æ–Ω–∫–∞ ROW —Å–æ–¥–µ—Ä–∂–∏—Ç –†–ï–ê–õ–¨–ù–´–ï –Ω–æ–º–µ—Ä–∞ —Å—Ç—Ä–æ–∫ Excel. –ò—Å–ø–æ–ª—å–∑—É–π –∏–º–µ–Ω–Ω–æ —ç—Ç–∏ –Ω–æ–º–µ—Ä–∞ –≤ –æ–ø–µ—Ä–∞—Ü–∏—è—Ö!

–°–æ–¥–µ—Ä–∂–∏–º–æ–µ:
{file_content}

---
–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {instruction}

–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç–∞–±–ª–∏—Ü—É –∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π JSON —Å –æ–ø–µ—Ä–∞—Ü–∏—è–º–∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.
–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
```json
{{
  "filename": "{filename}",
  "operations": [
    {{"action": "delete_row", "row": N}},
    ...
  ]
}}
```

–î–æ—Å—Ç—É–ø–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏:
- delete_row: —É–¥–∞–ª–∏—Ç—å —Å—Ç—Ä–æ–∫—É (row = –Ω–æ–º–µ—Ä —Å—Ç—Ä–æ–∫–∏)
- edit_cell: –∏–∑–º–µ–Ω–∏—Ç—å —è—á–µ–π–∫—É (row, col, value)
- add_row: –¥–æ–±–∞–≤–∏—Ç—å —Å—Ç—Ä–æ–∫—É (data = –º–∞—Å—Å–∏–≤ –∑–Ω–∞—á–µ–Ω–∏–π, after_row = –ø–æ—Å–ª–µ –∫–∞–∫–æ–π —Å—Ç—Ä–æ–∫–∏)
"""
            messages.append({"role": "user", "content": context})
            logger.info(f"Router: —Å–ª–æ–∂–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ LLM. –§–∞–π–ª: {filename}")
            return None, messages

        _, operations = parse_excel_command(last_user_msg)

        if operations:
            result = edit_excel(filename, operations, role=role)

            if result.get("success"):
                ops_desc = ", ".join([op["action"] for op in operations])
                return f"–í—ã–ø–æ–ª–Ω–µ–Ω–æ ({ops_desc})!\n\n–°–∫–∞—á–∞—Ç—å: {result['download_url']}", messages
            else:
                return f"–û—à–∏–±–∫–∞: {result.get('error')}", messages
        else:
            file_content = read_excel_for_edit(filename, role=role)
            instruction = _get_edit_instruction(last_user_msg, filename)

            context = f"""–§–∞–π–ª: {filename}

–í–ê–ñ–ù–û: –ö–æ–ª–æ–Ω–∫–∞ ROW —Å–æ–¥–µ—Ä–∂–∏—Ç –†–ï–ê–õ–¨–ù–´–ï –Ω–æ–º–µ—Ä–∞ —Å—Ç—Ä–æ–∫ Excel. –ò—Å–ø–æ–ª—å–∑—É–π –∏–º–µ–Ω–Ω–æ —ç—Ç–∏ –Ω–æ–º–µ—Ä–∞ –≤ –æ–ø–µ—Ä–∞—Ü–∏—è—Ö!

–°–æ–¥–µ—Ä–∂–∏–º–æ–µ:
{file_content}

---
–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è: {instruction}

–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π JSON —Å –æ–ø–µ—Ä–∞—Ü–∏—è–º–∏:
```json
{{
  "filename": "{filename}",
  "operations": [...]
}}
```
"""
            messages.append({"role": "user", "content": context})
            return None, messages

    if re.search(r"(–Ω–∞–π–¥–∏|–ø–æ–∏—Å–∫|–Ω–∞–π–¥–∏ –≤ —Ñ–∞–π–ª–∞—Ö|search)\s+\w", last_user_msg, re.I):
        query = re.sub(r"(–Ω–∞–π–¥–∏|–ø–æ–∏—Å–∫|–Ω–∞–π–¥–∏ –≤ —Ñ–∞–π–ª–∞—Ö|search)\s*", "", last_user_msg, flags=re.I).strip()
        if query:
            result = perform_search(query, role)
            return result, messages

    if re.search(r"(–∑–∞–ø–æ–º–Ω–∏|—Å–æ—Ö—Ä–∞–Ω–∏ —Ñ–∞–∫—Ç|–¥–æ–±–∞–≤—å –≤ –ø–∞–º—è—Ç—å)", last_user_msg, re.I):
        fact = re.sub(r"(–∑–∞–ø–æ–º–Ω–∏|—Å–æ—Ö—Ä–∞–Ω–∏ —Ñ–∞–∫—Ç|–¥–æ–±–∞–≤—å –≤ –ø–∞–º—è—Ç—å)\s*", "", last_user_msg, flags=re.I).strip()
        if fact and vector_store.is_connected():
            result = vector_store.add_memory(fact, "general", role)
            return result.get("message", "–û—à–∏–±–∫–∞"), messages

    if re.search(r"(—Å–≤–æ–¥–∫–∞|—Å–≤–æ–¥–∫—É|–æ–±–∑–æ—Ä|summary).*(—Ñ–∞–π–ª|–¥–æ–∫—É–º–µ–Ω—Ç|–≤—Å–µ—Ö)", last_user_msg, re.I):
        result = await process_multiple_files(last_user_msg, role, top_n=20)
        return result, messages

    if re.search(r"(—Å—Ä–∞–≤–Ω–∏|—Å—Ä–∞–≤–Ω–µ–Ω–∏–µ|compare)", last_user_msg, re.I):
        result = await process_multiple_files(last_user_msg, role, top_n=10)
        return result, messages

    edit_match = re.search(
        r'```json\s*(\{[\s\S]*?"operations"[\s\S]*?\})\s*```',
        last_user_msg,
        re.I
    )
    if edit_match:
        try:
            edit_data = json.loads(edit_match.group(1))
            filename = edit_data.get("filename")
            operations = edit_data.get("operations", [])

            if filename and operations:
                result = edit_excel(filename, operations, role=role)
                if result.get("success"):
                    return f"–§–∞–π–ª –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω!\n\n–°–∫–∞—á–∞—Ç—å: {result['download_url']}", messages
                else:
                    return f"–û—à–∏–±–∫–∞: {result.get('error')}", messages
        except json.JSONDecodeError as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")

    if any(ext in last_user_msg.lower() for ext in [".xlsx", ".xls"]):
        filename = _extract_filename_from_text(last_user_msg, role)
        if filename:
            content = read_excel(filename, role=role)
            return content, messages

    file_result = try_handle_file_command(last_user_msg, role)
    if file_result:
        return file_result, messages

    return None, messages
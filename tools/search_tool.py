# tools/search_tool.py
from vector_store.wv_store import WeaviateStore
from tools.chunking_tool import chunk_text, read_file_content, BASE_FILES_DIR
from typing import List, Dict, Optional
import logging
import os

logger = logging.getLogger(__name__)

store = WeaviateStore()


def brute_force_search_files(query: str, top_n: int = 5) -> List[Dict]:
    """
    ĞŸÑ€Ğ¾ÑÑ‚Ğ¾Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞº Ğ¿Ğ¾Ğ´ÑÑ‚Ñ€Ğ¾ĞºĞ¸ query Ğ¿Ğ¾ Ğ²ÑĞµĞ¼ Ñ„Ğ°Ğ¹Ğ»Ğ°Ğ¼ Ğ² BASE_FILES_DIR.
    Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ ÑĞ¿Ğ¸ÑĞ¾Ğº Ñ‡Ğ°Ğ½ĞºĞ¾Ğ² Ñ Ğ¿Ğ¾Ğ»ÑĞ¼Ğ¸: filename, chunk_index, content, score.
    """
    hits = []
    q = query.lower()

    for f in BASE_FILES_DIR.iterdir():
        if not f.is_file():
            continue

        content = read_file_content(f)
        if not content or content.startswith("ĞÑˆĞ¸Ğ±ĞºĞ°"):
            continue

        if q in content.lower():
            start = content.lower().index(q)
            begin = max(0, start - 120)
            end = min(len(content), start + len(q) + 120)
            snippet = content[begin:end].replace("\n", " ").strip()
            hits.append({
                "filename": f.name,
                "chunk_index": 0,
                "content": snippet,
                "score": 1.0
            })
            if len(hits) >= top_n:
                break

    return hits


def search_documents(query: str, user_id: Optional[str] = None, top_n: int = 5) -> List[Dict]:
    """
    Ğ¡ĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞº Ñ fallback Ğ½Ğ° Ğ¿Ñ€ÑĞ¼Ğ¾Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞº Ğ¿Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğ°Ğ¼.
    Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ ÑĞ¿Ğ¸ÑĞ¾Ğº Ñ‡Ğ°Ğ½ĞºĞ¾Ğ² Ñ Ğ¿Ğ¾Ğ»ÑĞ¼Ğ¸: filename, chunk_index, content, score.
    """
    if not store.is_connected():
        logger.warning("Weaviate Ğ½Ğµ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½. Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ¿Ñ€ÑĞ¼Ğ¾Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞº Ğ¿Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğ°Ğ¼.")
        return brute_force_search_files(query, top_n=top_n)

    logger.info(f"ĞŸĞ¾Ğ¸ÑĞº Ğ² Weaviate: '{query}' Ğ´Ğ»Ñ user_id={user_id}")
    results = store.search_documents(query, user_id=user_id, limit=top_n)

    # fallback Ğ½Ğ° Ğ¿Ñ€ÑĞ¼Ğ¾Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞº, ĞµÑĞ»Ğ¸ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸ĞºĞ° Ğ¿ÑƒÑÑ‚Ğ°Ñ
    if not results:
        logger.info("Weaviate Ğ²ĞµÑ€Ğ½ÑƒĞ» 0 Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ². ĞŸÑ€Ğ¾Ğ±ÑƒĞµĞ¼ Ğ¿Ñ€ÑĞ¼Ğ¾Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞº Ğ¿Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğ°Ğ¼.")
        results = brute_force_search_files(query, top_n=top_n)

    return results


def perform_search(query: str, user_id: Optional[str] = None, top_n: int = 5) -> str:
    """
    Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ Ñ€Ğ¾ÑƒÑ‚ĞµÑ€Ğ°. Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ğ¾Ğµ Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ¿Ğ¾Ğ¸ÑĞºĞ°.
    """
    results = search_documents(query, user_id=user_id, top_n=top_n)

    if not results:
        return "âŒ ĞĞ¸Ñ‡ĞµĞ³Ğ¾ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ğ² Ğ²Ğ°ÑˆĞ¸Ñ… Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ…."

    lines = ["ğŸ” **Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾Ğ¸ÑĞºĞ°:**\n"]
    for i, doc in enumerate(results, 1):
        content_preview = doc["content"][:300]
        if len(doc["content"]) > 300:
            content_preview += "..."
        lines.append(
            f"ğŸ“„ **{i}. {doc.get('filename', '(unnamed)')}** (chunk {doc.get('chunk_index', 0)})\n"
            f"{content_preview}\n"
        )

    return "\n".join(lines)
import sys
import logging
from pathlib import Path
from typing import List
from dotenv import load_dotenv

load_dotenv()

sys.path.insert(0, str(Path(__file__).parent.parent))

from vector_store import vector_store
from tools.utils import BASE_FILES_DIR
from tools.file_tool import read_file
from tools.excel_tool import read_excel

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def chunk_text_with_overlap(text: str, max_words: int = 500, overlap_words: int = 50) -> List[str]:
    words = text.split()
    if len(words) <= max_words:
        return [text]

    chunks = []
    start = 0

    while start < len(words):
        end = min(start + max_words, len(words))
        chunks.append(" ".join(words[start:end]))
        start += max_words - overlap_words

    return chunks

def is_error_response(content: str) -> bool:
    if not content:
        return True
    error_prefixes = ("ÐžÑˆÐ¸Ð±ÐºÐ°", "File error", "Error")
    return content.strip().startswith(error_prefixes)

def index_file(filepath: Path, user_id: str = "default") -> dict:

    if not filepath.exists():
        return {"success": False, "message": "Ð¤Ð°Ð¹Ð» Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½"}

    try:
        suffix = filepath.suffix.lower()

        # ==========================
        # Read file
        # ==========================
        if suffix in (".xlsx", ".xls"):
            content = read_excel(filepath.name)
        else:
            content = read_file(filepath)

        if is_error_response(content):
            logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ñ‡Ñ‚ÐµÐ½Ð¸Ñ {filepath.name}: {content}")
            return {"success": False, "message": content}

        if suffix in (".xlsx", ".xls", ".csv"):
            result = vector_store.add_document(
                content=content,
                filename=filepath.name,
                filetype=suffix[1:],
                user_id=user_id,
                metadata={
                    "chunk_index": 0,
                    "total_chunks": 1,
                    "source_path": str(filepath),
                    "is_table": True
                }
            )

            if result.get("success"):
                logger.info(f"ðŸ“Š {filepath.name}: Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ð° Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð° Ñ†ÐµÐ»Ð¸ÐºÐ¾Ð¼")
                return {"success": True, "chunks": 1}

            return {"success": False, "message": result.get("message")}

        # ==========================
        # Normal text â†’ chunking
        # ==========================
        chunks = chunk_text_with_overlap(content)
        success_chunks = 0

        for idx, chunk in enumerate(chunks):
            result = vector_store.add_document(
                content=chunk,
                filename=filepath.name,
                filetype=suffix[1:],
                user_id=user_id,
                metadata={
                    "chunk_index": idx,
                    "total_chunks": len(chunks),
                    "source_path": str(filepath),
                }
            )
            if result.get("success"):
                success_chunks += 1

        logger.info(f"ðŸ“„ {filepath.name}: {success_chunks}/{len(chunks)} Ñ‡Ð°Ð½ÐºÐ¾Ð²")
        return {"success": True, "chunks": success_chunks}

    except Exception as e:
        logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¸Ð½Ð´ÐµÐºÑÐ°Ñ†Ð¸Ð¸ {filepath.name}: {e}")
        return {"success": False, "message": str(e)}

def index_all_files(user_id: str = "default"):

    if not vector_store.is_connected():
        if not vector_store.connect():
            logger.error("âŒ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡Ð¸Ñ‚ÑŒÑÑ Ðº Weaviate")
            return

    supported = {".txt", ".pdf", ".docx", ".xlsx", ".xls", ".md", ".csv", ".log"}

    files = [
        f for f in BASE_FILES_DIR.iterdir()
        if f.is_file() and f.suffix.lower() in supported
    ]

    if not files:
        logger.warning("âš ï¸ ÐÐµÑ‚ Ñ„Ð°Ð¹Ð»Ð¾Ð² Ð´Ð»Ñ Ð¸Ð½Ð´ÐµÐºÑÐ°Ñ†Ð¸Ð¸")
        return

    success = 0
    errors = 0

    for f in files:
        result = index_file(f, user_id)
        if result.get("success"):
            success += 1
        else:
            errors += 1

    stats = vector_store.get_stats()

    logger.info("=" * 60)
    logger.info(f"âœ” Ð£ÑÐ¿ÐµÑˆÐ½Ð¾: {success} | âœ˜ ÐžÑˆÐ¸Ð±ÐºÐ¸: {errors}")
    logger.info(f"ðŸ“Š Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°: {stats}")
    logger.info("=" * 60)


def reindex_all(user_id: str = "default"):
    logger.info("ðŸ§¹ ÐžÑ‡Ð¸ÑÑ‚ÐºÐ° ÑÑ‚Ð°Ñ€Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…â€¦")
    vector_store.clear_user_data(user_id)

    logger.info("ðŸ”„ ÐŸÐµÑ€ÐµÐ¸Ð½Ð´ÐµÐºÑÐ°Ñ†Ð¸Ñâ€¦")
    index_all_files(user_id)

    logger.info("âœ” Ð“Ð¾Ñ‚Ð¾Ð²Ð¾")


if __name__ == "__main__":
    if not vector_store.connect():
        print("âŒ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð´ÐºÐ»ÑŽÑ‡Ð¸Ñ‚ÑŒÑÑ")
        sys.exit(1)

    uid = sys.argv[1] if len(sys.argv) > 1 else "default"
    reindex_all(uid)
    vector_store.disconnect()
# agent/agent.py
from agent.memory import memory
from agent.router import route_message
from agent.prompts import SYSTEM_PROMPT
from agent.models import send_to_llm
from vector_store import vector_store
import logging

logger = logging.getLogger(__name__)

DOC_INDEX_USER_ID = "default"  # ‚úÖ –û–±—â–∏–π –∏–Ω–¥–µ–∫—Å –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤

async def agent_process(prompt: str, user_id: str):
    history = memory.get_history(user_id) or []

    rag_context = _get_rag_context(prompt, user_id)  # ‚úÖ –ü–µ—Ä–µ–¥–∞—ë–º user_id

    enhanced_system_prompt = SYSTEM_PROMPT
    if rag_context:
        enhanced_system_prompt += f"\n\nüìö **–†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:**\n{rag_context}"

    messages = [{"role": "system", "content": enhanced_system_prompt}] + history
    messages.append({"role": "user", "content": prompt})

    # ‚úÖ –ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞ - –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω–∞—è –¥–ª—è user_id
    if vector_store.is_connected():
        vector_store.add_chat_message(prompt, "user", user_id)

    result, updated_messages = await route_message(messages, user_id)

    if result is None:
        logger.info("–û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞ LLM —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º")
        result = await send_to_llm(updated_messages)
        updated_messages.append({"role": "assistant", "content": result})

    # ‚úÖ –ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞ - –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω–∞—è –¥–ª—è user_id
    if vector_store.is_connected():
        vector_store.add_chat_message(result, "assistant", user_id)

    memory.set_history(user_id, updated_messages[-50:])
    return result


def _get_rag_context(query: str, user_id: str, max_length: int = 2000) -> str:  # ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω user_id
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ –æ–±—â–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏ –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω–æ–π –ø–∞–º—è—Ç–∏/–∏—Å—Ç–æ—Ä–∏–∏"""
    if not vector_store.is_connected():
        return ""

    try:
        context_parts = []

        # ‚úÖ –î–æ–∫—É–º–µ–Ω—Ç—ã - –æ–±—â–∏–µ –¥–ª—è –≤—Å–µ—Ö (default)
        doc_results = vector_store.search_documents(query, DOC_INDEX_USER_ID, limit=3)
        if doc_results:
            context_parts.append("**–ò–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:**")
            for doc in doc_results:
                content_preview = doc["content"][:300]
                if len(doc["content"]) > 300:
                    content_preview += "..."
                context_parts.append(f"‚Ä¢ [{doc['filename']}]: {content_preview}")

        # ‚úÖ –ü–∞–º—è—Ç—å - –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω–∞—è –¥–ª—è user_id
        user_facts = vector_store.search_memory(query, user_id, limit=2)
        if user_facts:
            context_parts.append("\n**–ß—Ç–æ —è –∑–Ω–∞—é –æ –≤–∞—Å:**")
            for fact in user_facts:
                context_parts.append(f"‚Ä¢ {fact}")

        # ‚úÖ –ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞ - –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω–∞—è –¥–ª—è user_id
        chat_history = vector_store.search_chat_history(query, user_id, limit=2)
        if chat_history:
            context_parts.append("\n**–ò–∑ –ø—Ä–æ—à–ª—ã—Ö —Ä–∞–∑–≥–æ–≤–æ—Ä–æ–≤:**")
            for chat in chat_history:
                message_preview = chat["message"][:200]
                if len(chat["message"]) > 200:
                    message_preview += "..."
                context_parts.append(f"‚Ä¢ {message_preview}")

        full_context = "\n".join(context_parts)
        if len(full_context) > max_length:
            full_context = full_context[:max_length] + "..."
        return full_context

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è RAG –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {e}")
        return ""